{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 woth autoencoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input, SimpleRNN, LSTM, GRU, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load the cleaned dataset\n",
    "df = pd.read_csv(\"swiss_no_outliers_and_cleaned.csv\")\n",
    "\n",
    "# Select features and target variable\n",
    "X = df[[\"Rooms\", \"Footage\", \"Distance_to_City_Center(km)\", \"Address_Latitude\", \"Address_Longitude\"]]\n",
    "y = df[\"Rent\"]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the input data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Define the input layer\n",
    "input_data = Input(shape=(5,))\n",
    "\n",
    "# Define the encoder\n",
    "encoded = Dense(64, activation='relu')(input_data)\n",
    "encoded = Dense(32, activation='relu')(encoded)\n",
    "\n",
    "# Define the bottleneck (compressed representation)\n",
    "bottleneck = Dense(8, activation='relu')(encoded)\n",
    "\n",
    "# Define the decoder\n",
    "decoded = Dense(32, activation='relu')(bottleneck)\n",
    "decoded = Dense(64, activation='relu')(decoded)\n",
    "\n",
    "# Define the output layer\n",
    "output_data = Dense(5, activation='linear')(decoded)\n",
    "\n",
    "# Create the autoencoder model\n",
    "autoencoder = Model(input_data, output_data)\n",
    "autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "\n",
    "# Train the autoencoder model\n",
    "autoencoder.fit(X_scaled, X_scaled, epochs=100, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Extract the encoder part of the autoencoder\n",
    "encoder = Model(input_data, bottleneck)\n",
    "\n",
    "# Generate a lower-dimensional representation of your input data\n",
    "X_encoded = encoder.predict(X_scaled)\n",
    "\n",
    "# Reshape the encoded data into a suitable format for RNNs, LSTMs, or GRUs\n",
    "timesteps = 2\n",
    "features = 4\n",
    "X_encoded_reshaped = X_encoded.reshape((-1, timesteps, features))\n",
    "\n",
    "# Split the reshaped data into training and testing sets\n",
    "X_encoded_train, X_encoded_test, y_train, y_test = train_test_split(X_encoded_reshaped, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a function to create a model based on the model type\n",
    "def create_model(model_type, units):\n",
    "    model = Sequential()\n",
    "\n",
    "    if model_type == \"RNN\":\n",
    "        model.add(SimpleRNN(units, input_shape=(timesteps, features), activation='relu', return_sequences=True))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(SimpleRNN(units, activation='relu'))\n",
    "    elif model_type == \"LSTM\":\n",
    "        model.add(LSTM(units, input_shape=(timesteps, features), activation='relu', return_sequences=True))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units, activation='relu'))\n",
    "    elif model_type == \"GRU\":\n",
    "        model.add(GRU(units, input_shape=(timesteps, features), activation='relu', return_sequences=True))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(GRU(units, activation='relu'))\n",
    "\n",
    "    model.add(Dense(units, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=0.001))\n",
    "    return model\n",
    "\n",
    "# Train the models and compare their performance\n",
    "model_types = [\"RNN\", \"LSTM\", \"GRU\"]\n",
    "units = 32\n",
    "epochs = 200\n",
    "batch_size = 32\n",
    "\n",
    "results = {}\n",
    "\n",
    "for model_type in model_types:\n",
    "    print(f\"Training {model_type} model...\")\n",
    "    model = create_model(model_type, units)\n",
    "    model.fit(X_encoded_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2, verbose=0)\n",
    "\n",
    "    y_pred_train = model.predict(X_encoded_train)\n",
    "    y_pred_test = model.predict(X_encoded_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "    mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "    r2_train = r2_score(y_train, y_pred_train)\n",
    "    r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "    results[model_type] = {\n",
    "        \"mse_train\": mse_train,\n",
    "        \"mse_test\": mse_test,\n",
    "        \"r2_train\": r2_train,\n",
    "        \"r2_test\": r2_test,\n",
    "    }\n",
    "\n",
    "# Print the results\n",
    "for model_type, result in results.items():\n",
    "    print(f\"{model_type} model:\")\n",
    "    print(f\" MSE (Train): {result['mse_train']:.2f}\")\n",
    "    print(f\" MSE (Test): {result['mse_test']:.2f}\")\n",
    "    print(f\" R2 (Train): {result['r2_train']:.2f}\")\n",
    "    print(f\" R2 (Test): {result['r2_test']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 2 \n",
    "##Version mit RandomizedSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input, SimpleRNN, LSTM, GRU, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load the cleaned dataset\n",
    "df = pd.read_csv(\"swiss_no_outliers_and_cleaned.csv\")\n",
    "\n",
    "# Select features and target variable\n",
    "X = df[[\"Rooms\", \"Footage\", \"Distance_to_City_Center(km)\", \"Address_Latitude\", \"Address_Longitude\"]]\n",
    "y = df[\"Rent\"]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the input data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Define the input layer\n",
    "input_data = Input(shape=(5,))\n",
    "\n",
    "# Define the encoder\n",
    "encoded = Dense(64, activation='relu')(input_data)\n",
    "encoded = Dense(32, activation='relu')(encoded)\n",
    "encoded = Dense(16, activation='relu')(encoded)\n",
    "\n",
    "# Define the bottleneck (compressed representation)\n",
    "bottleneck = Dense(8, activation='relu')(encoded)\n",
    "\n",
    "# Define the decoder\n",
    "decoded = Dense(16, activation='relu')(bottleneck)\n",
    "decoded = Dense(32, activation='relu')(decoded)\n",
    "decoded = Dense(64, activation='relu')(decoded)\n",
    "\n",
    "# Define the output layer\n",
    "output_data = Dense(5, activation='linear')(decoded)\n",
    "\n",
    "# Create the autoencoder model\n",
    "autoencoder = Model(input_data, output_data)\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the autoencoder model\n",
    "autoencoder.fit(X_scaled, X_scaled, epochs=100, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Extract the encoder part of the autoencoder\n",
    "encoder = Model(input_data, bottleneck)\n",
    "\n",
    "# Generate a lower-dimensional representation of your input data\n",
    "X_encoded = encoder.predict(X_scaled)\n",
    "\n",
    "# Reshape the encoded data into a suitable format for RNNs, LSTMs, or GRUs\n",
    "timesteps = 2\n",
    "features = 4\n",
    "X_encoded_reshaped = X_encoded.reshape((-1, timesteps, features))\n",
    "\n",
    "# Split the reshaped data into training and testing sets\n",
    "X_encoded_train, X_encoded_test, y_train, y_test = train_test_split(X_encoded_reshaped, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Import necessary libraries\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "# Modify the create_model function to accept hyperparameters as arguments\n",
    "def create_model(model_type=\"LSTM\", units=128, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "\n",
    "    if model_type == \"RNN\":\n",
    "        model.add(SimpleRNN(units, input_shape=(timesteps, features), activation='relu', return_sequences=True))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(SimpleRNN(units, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    elif model_type == \"LSTM\":\n",
    "        model.add(LSTM(units, input_shape=(timesteps, features), activation='relu', return_sequences=True))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(LSTM(units, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    elif model_type == \"GRU\":\n",
    "        model.add(GRU(units, input_shape=(timesteps, features), activation='relu', return_sequences=True))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(GRU(units, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=learning_rate))\n",
    "    return model\n",
    "\n",
    "# Import necessary libraries\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "# Wrap the create_model function in KerasRegressor\n",
    "model = KerasRegressor(build_fn=create_model, verbose=0)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'model_type': ['RNN', 'LSTM', 'GRU'],\n",
    "    'units': [64, 128, 256, 512, 1024],\n",
    "    'dropout_rate': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    'learning_rate': [0.05, 0.01, 0.001, 0.0001],\n",
    "    'batch_size': [16, 32, 64, 128],\n",
    "    'epochs': [50, 100, 200],\n",
    "}\n",
    "\n",
    "\n",
    "# Create the RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=10, n_jobs=-1, cv=3, scoring='neg_mean_squared_error', random_state=42)\n",
    "\n",
    "# Fit the random search to the data\n",
    "random_search_result = random_search.fit(X_encoded_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best parameters found: \", random_search_result.best_params_)\n",
    "\n",
    "# Retrieve the best model\n",
    "best_model = random_search_result.best_estimator_.model\n",
    "best_model.save(\"best_model.h5\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = best_model.predict(X_encoded_train)\n",
    "y_pred_test = best_model.predict(X_encoded_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "# Print the results\n",
    "print(\"Best model:\")\n",
    "print(f\" MSE (Train): {mse_train:.2f}\")\n",
    "print(f\" MSE (Test): {mse_test:.2f}\")\n",
    "print(f\" R2 (Train): {r2_train:.2f}\")\n",
    "print(f\" R2 (Test): {r2_test:.2f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

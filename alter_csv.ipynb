{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b0baf7d-a46a-4f30-82ca-11a06732ad25",
   "metadata": {},
   "source": [
    "# Alter data in CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7df4a6-2c27-41a6-9049-8c83b380c1ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849c4f6f-4a7d-4440-8872-ad6c523411c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cantons = [\"zuerich\", \"bern\", \"luzern\", \"uri\", \"schwyz\", \"obwalden\", \"nidwalden\", \"glarus\", \"zug\", \"freiburg\", \n",
    "           \"solothurn\", \"basel-stadt\", \"basel-landschaft\", \"schaffhausen\", \"appenzell-ai\", \n",
    "           \"appenzell-ar\", \"st-gallen\", \"graubuenden\", \"aargau\", \"thurgau\", \"tessin\", \"waadt\", \"wallis\", \n",
    "           \"neuenburg\", \"genf\", \"jura\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6715e0-d299-495a-a077-b42ddfe46bb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "canton = \"solothurn\"\n",
    "print(canton)\n",
    "filename = f\"{canton}.csv\"\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "# Extract the first column as a list\n",
    "first_col = df.iloc[:, 0].tolist()\n",
    "\n",
    "# Separate each value in the list using the specified rules\n",
    "separated_values = []\n",
    "for i, value in enumerate(first_col):\n",
    "    #print(str(i))\n",
    "    parts = [i]  # add index as the first entry\n",
    "    current_part = \"\"\n",
    "    if isinstance(value, str):\n",
    "        for char in value:\n",
    "            if char == \",\":\n",
    "                if current_part != \"\":\n",
    "                    parts.append(int(current_part))\n",
    "                    current_part = \"\"\n",
    "            elif char == \" \":\n",
    "                continue\n",
    "            else:\n",
    "                current_part += char\n",
    "        if current_part != \"\":\n",
    "            parts.append(int(current_part))\n",
    "        elif len(parts) < 3:  # add a 0 if the entry has no value\n",
    "            parts.append(0)\n",
    "        separated_values.append(parts)\n",
    "    else: continue\n",
    "\n",
    "# Check each row and modify the values as needed\n",
    "for i, values in enumerate(separated_values):\n",
    "    if len(values) >= 3 and values[2] < 10:\n",
    "        combined_value = float(f\"{values[1]}.{values[2]}\")\n",
    "        separated_values[i] = [values[0], combined_value] + values[3:]\n",
    "    elif len(values) >= 2 and values[1] < 25:\n",
    "        float_value = float(values[1])\n",
    "        separated_values[i] = [values[0], float_value] + values[2:]\n",
    "\n",
    "# Remove any row that has less than 4 entries\n",
    "separated_values = [row for row in separated_values if len(row) >= 4]\n",
    "\n",
    "new_df = pd.DataFrame(separated_values, columns=[\"Index\", \"Rooms\", \"Footage\", \"Rent\"])\n",
    "#new_df[\"Canton\"] = canton  # add a column for the canton\n",
    "\n",
    "new_col1 = df.loc[:,\"header\"]\n",
    "new_col2 = df.loc[:,\"header\"]\n",
    "new_col3 = df.loc[:,\"header\"]\n",
    "\n",
    "# Insert the new columns at the beginning of the dataframe\n",
    "df.insert(1, 'Rent', new_col3)\n",
    "df.insert(1, 'Footage', new_col2)\n",
    "df.insert(1, 'Rooms', new_col1)\n",
    "df = df.drop(\"header\",axis=1)\n",
    "\n",
    "length = len(df.loc[:,'Rooms'])\n",
    "for i in range(length):\n",
    "    #print(str(i))\n",
    "    if i in new_df['Index'].values:\n",
    "        index = new_df.index[new_df['Index'] == i][0]\n",
    "        #print(str(index))\n",
    "        df.loc[i,\"Rooms\"]=new_df.loc[index,\"Rooms\"]\n",
    "        df.loc[i,\"Footage\"]=new_df.loc[index,\"Footage\"]\n",
    "        df.loc[i,\"Rent\"]=new_df.loc[index,\"Rent\"]\n",
    "    else:\n",
    "        df.loc[i,\"Rooms\"]=0\n",
    "        df.loc[i,\"Footage\"]=0\n",
    "        df.loc[i,\"Rent\"]=0\n",
    "\n",
    "for i in range(length):\n",
    "    if df.loc[i,\"Rooms\"]==0:\n",
    "        df = df.drop(i)\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "# Split the address column into street, city, and canton columns\n",
    "df[['street', 'city', 'canton']] = df['address'].str.split(',', 2, expand=True)\n",
    "\n",
    "# Strip whitespace from the new columns\n",
    "df['street'] = df['street'].str.strip()\n",
    "df['city'] = df['city'].str.strip()\n",
    "df['canton'] = df['canton'].str.strip()\n",
    "\n",
    "# Remove trailing \",\" from the new columns\n",
    "df['street'] = df['street'].str.replace(r',$', '')\n",
    "df['city'] = df['city'].str.replace(r',$', '')\n",
    "df['canton'] = df['canton'].str.replace(r',$', '')\n",
    "\n",
    "# Move data to the right if the canton column is empty\n",
    "mask = df['canton'].isnull()\n",
    "df.loc[mask, 'canton'] = df['city']\n",
    "df.loc[mask, 'city'] = df['street']\n",
    "df.loc[mask, 'street'] = ''\n",
    "print(df)\n",
    "filename = f\"{canton}_new.csv\"\n",
    "df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c97e249-9962-4ed6-953b-65dcd70a2e6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_combined = []\n",
    "for canton in cantons:\n",
    "    #canton = \"nidwalden\"\n",
    "    print(canton)\n",
    "    filename = f\"{canton}.csv\"\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    # Extract the first column as a list\n",
    "    first_col = df.iloc[:, 0].tolist()\n",
    "\n",
    "    # Separate each value in the list using the specified rules\n",
    "    separated_values = []\n",
    "    for i, value in enumerate(first_col):\n",
    "        #print(str(i))\n",
    "        parts = [i]  # add index as the first entry\n",
    "        current_part = \"\"\n",
    "        if isinstance(value, str):\n",
    "            for char in value:\n",
    "                if char == \",\":\n",
    "                    if current_part != \"\":\n",
    "                        parts.append(int(current_part))\n",
    "                        current_part = \"\"\n",
    "                elif char == \" \":\n",
    "                    continue\n",
    "                else:\n",
    "                    current_part += char\n",
    "            if current_part != \"\":\n",
    "                parts.append(int(current_part))\n",
    "            elif len(parts) < 3:  # add a 0 if the entry has no value\n",
    "                parts.append(0)\n",
    "            separated_values.append(parts)\n",
    "        else: continue\n",
    "            \n",
    "    # Check each row and modify the values as needed\n",
    "    for i, values in enumerate(separated_values):\n",
    "        if len(values) >= 3 and values[2] < 10:\n",
    "            combined_value = float(f\"{values[1]}.{values[2]}\")\n",
    "            separated_values[i] = [values[0], combined_value] + values[3:]\n",
    "        elif len(values) >= 2 and values[1] < 25:\n",
    "            float_value = float(values[1])\n",
    "            separated_values[i] = [values[0], float_value] + values[2:]\n",
    "\n",
    "    # Remove any row that has less than 4 entries\n",
    "    separated_values = [row for row in separated_values if len(row) >= 4]\n",
    "\n",
    "    new_df = pd.DataFrame(separated_values, columns=[\"Index\", \"Rooms\", \"Footage\", \"Rent\"])\n",
    "    #new_df[\"Canton\"] = canton  # add a column for the canton\n",
    "\n",
    "    new_col1 = df.loc[:,\"header\"]\n",
    "    new_col2 = df.loc[:,\"header\"]\n",
    "    new_col3 = df.loc[:,\"header\"]\n",
    "\n",
    "    # Insert the new columns at the beginning of the dataframe\n",
    "    df.insert(1, 'Rent', new_col3)\n",
    "    df.insert(1, 'Footage', new_col2)\n",
    "    df.insert(1, 'Rooms', new_col1)\n",
    "    df = df.drop(\"header\",axis=1)\n",
    "\n",
    "    length = len(df.loc[:,'Rooms'])\n",
    "    for i in range(length):\n",
    "        #print(str(i))\n",
    "        if i in new_df['Index'].values:\n",
    "            index = new_df.index[new_df['Index'] == i][0]\n",
    "            #print(str(index))\n",
    "            df.loc[i,\"Rooms\"]=new_df.loc[index,\"Rooms\"]\n",
    "            df.loc[i,\"Footage\"]=new_df.loc[index,\"Footage\"]\n",
    "            df.loc[i,\"Rent\"]=new_df.loc[index,\"Rent\"]\n",
    "        else:\n",
    "            df.loc[i,\"Rooms\"]=0\n",
    "            df.loc[i,\"Footage\"]=0\n",
    "            df.loc[i,\"Rent\"]=0\n",
    "\n",
    "    for i in range(length):\n",
    "        if df.loc[i,\"Rooms\"]==0:\n",
    "            df = df.drop(i)\n",
    "\n",
    "    df = df.reset_index(drop=True)\n",
    "    # Split the address column into street, city, and canton columns\n",
    "    df[['street', 'city', 'canton']] = df['address'].str.split(',', 2, expand=True)\n",
    "\n",
    "    # Strip whitespace from the new columns\n",
    "    df['street'] = df['street'].str.strip()\n",
    "    df['city'] = df['city'].str.strip()\n",
    "    df['canton'] = df['canton'].str.strip()\n",
    "\n",
    "    # Remove trailing \",\" from the new columns\n",
    "    df['street'] = df['street'].str.replace(r',$', '')\n",
    "    df['city'] = df['city'].str.replace(r',$', '')\n",
    "    df['canton'] = df['canton'].str.replace(r',$', '')\n",
    "\n",
    "    # Move data to the right if the canton column is empty\n",
    "    mask = df['canton'].isnull()\n",
    "    df.loc[mask, 'canton'] = df['city']\n",
    "    df.loc[mask, 'city'] = df['street']\n",
    "    df.loc[mask, 'street'] = ''\n",
    "    \n",
    "    df_combined.append(df)\n",
    "    #print(df)\n",
    "# Concatenate all the DataFrames into a single DataFrame\n",
    "df_combined_swiss = pd.concat(df_combined, ignore_index=True)\n",
    "df_combined_swiss.to_csv(\"swiss.csv\", index=False)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4772eb0-75c2-4956-97ec-98b0759f9d0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the base URL for the Overpass API\n",
    "base_url = \"https://nominatim.openstreetmap.org/search\"\n",
    "headers = headers = ({'User-Agent': 'Mozilla/5.0 (iPad; CPU OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c890ff7-20d0-4234-b99c-1b6228478d08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cantons = [\"zuerich\", \"bern\", \"luzern\", \"uri\", \"schwyz\", \"obwalden\", \"nidwalden\", \"glarus\", \"zug\", \"freiburg\", \n",
    "           \"solothurn\", \"basel-stadt\", \"basel-landschaft\", \"schaffhausen\", \"appenzell-ai\", \n",
    "           \"appenzell-ar\", \"st-gallen\", \"graubuenden\", \"aargau\", \"thurgau\", \"tessin\", \"waadt\", \"wallis\", \n",
    "           \"neuenburg\", \"genf\", \"jura\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829ab9ed-6f4a-4b8a-a782-1caca72caddf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to get latitude and longitude for a given address\n",
    "def get_lat_lng(address):\n",
    "    try:\n",
    "        params = {\"q\": address, \"format\": \"json\"}\n",
    "        response = requests.get(base_url, params=params, headers=headers)\n",
    "        data = response.json()\n",
    "        if data:\n",
    "            lat = float(data[0]['lat'])\n",
    "            lng = float(data[0]['lon'])\n",
    "            return lat, lng\n",
    "        else:\n",
    "            return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d506c9-489a-47b9-9233-92324e760666",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_lat_lng_from_city(city_postalcode):\n",
    "    try:\n",
    "        city, postalcode = city_postalcode.split()\n",
    "        params = {\"q\": f\"{city} {postalcode}\", \"format\": \"json\"}\n",
    "        response = requests.get(base_url, params=params, headers=headers)\n",
    "        data = response.json()\n",
    "        if data:\n",
    "            lat = float(data[0]['lat'])\n",
    "            lng = float(data[0]['lon'])\n",
    "            return lat, lng\n",
    "        else:\n",
    "            return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc4cb17-d6c5-49ca-b3c4-5284ee0067d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add new columns for latitude and longitude\n",
    "df[\"Latitude\"] = None\n",
    "df[\"Longitude\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7f824f-0284-410e-93f3-8a06e2ab099f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Iterate through the dataframe and update the latitude and longitude columns\n",
    "def update_lat_lng(df):\n",
    "    # Create columns for the address and city coordinates\n",
    "    df['Address_Latitude'] = ''\n",
    "    df['Address_Longitude'] = ''\n",
    "    df['City_Latitude'] = ''\n",
    "    df['City_Longitude'] = ''\n",
    "\n",
    "    # Iterate through the dataframe and update the latitude and longitude columns\n",
    "    for index, row in df.iterrows():\n",
    "        address = row[\"address\"]\n",
    "        city = row[\"city\"]\n",
    "        address_lat, address_lng = get_lat_lng(address)\n",
    "        time.sleep(1)\n",
    "        city_lat, city_lng = get_lat_lng(city)\n",
    "        df.at[index, \"Address_Latitude\"] = address_lat\n",
    "        df.at[index, \"Address_Longitude\"] = address_lng\n",
    "        df.at[index, \"City_Latitude\"] = city_lat\n",
    "        df.at[index, \"City_Longitude\"] = city_lng\n",
    "        if index % 100 == 0:\n",
    "            print(f\"Processed {index} rows\")\n",
    "        time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada28710-df44-42f1-ba98-051231279b17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = \"swiss.csv\"\n",
    "df = pd.read_csv(filename)\n",
    "update_lat_lng(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38bc4f1-c7a6-4101-8710-dbee2b91b5d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the updated dataframe to a new CSV file\n",
    "df.to_csv(\"swiss_with_coordinates.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa57ea9-5ebc-4f00-afe2-98934fd34717",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "df = pd.read_csv(\"swiss_with_coordinates.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d5b868-cdc0-4fe9-9d8e-7892de6adc99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Earth's radius in kilometers\n",
    "\n",
    "    # Convert degrees to radians\n",
    "    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
    "\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "\n",
    "    a = math.sin(dlat / 2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "\n",
    "    distance = R * c\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09061660-b06f-4a4d-af0d-a2e3e1624c38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['Distance_to_City_Center(km)'] = df.apply(\n",
    "    lambda row: haversine(\n",
    "        row['Address_Latitude'], row['Address_Longitude'],\n",
    "        row['City_Latitude'], row['City_Longitude']\n",
    "    ), axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496a1321-1a92-4a3a-a6f3-a4578d4b3339",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop rows with missing values in the specified columns\n",
    "df = df.dropna(subset=[\"Rooms\", \"Footage\", \"Rent\", \"address\",\"Distance_to_City_Center(km)\",\"Address_Latitude\",\"Address_Longitude\",\"City_Latitude\",\"City_Longitude\"])\n",
    "# Drop duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Function to remove outliers using the IQR method\n",
    "def remove_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "# Remove outliers in the specified columns\n",
    "df = remove_outliers(df, \"Rooms\")\n",
    "df = remove_outliers(df, \"Footage\")\n",
    "df = remove_outliers(df, \"Rent\")\n",
    "\n",
    "# Save the dataframe without outliers to a new CSV file\n",
    "df.to_csv(\"swiss_no_outliers_and_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1e4ce4-7884-4005-b7ac-7f14a8211f91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Visualize the distribution of the \"Rooms\", \"Footage\", and \"Rent\" columns using histograms:\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.histplot(df[\"Rooms\"], kde=True, bins=20)\n",
    "plt.title(\"Rooms Distribution\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.histplot(df[\"Footage\"], kde=True, bins=20)\n",
    "plt.title(\"Footage Distribution\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.histplot(df[\"Rent\"], kde=True, bins=20)\n",
    "plt.title(\"Rent Distribution\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcade9c-b42c-46d3-b7fc-233ed66ad64c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Visualize the relationship between \"Footage\" and \"Rent\" using a scatterplot:\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=\"Footage\", y=\"Rent\", data=df, hue=\"Rooms\")\n",
    "plt.title(\"Footage vs. Rent\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531c90c8-a590-408a-9bc3-52fa53178969",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Visualize the relationship between \"Rooms\" and \"Rent\" using a boxplot:\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=\"Rooms\", y=\"Rent\", data=df)\n",
    "plt.title(\"Rooms vs. Rent\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e902a33-fe16-441e-ba7f-9d4174937aa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a heatmap to visualize the correlation between numeric columns:\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(df.corr(), annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
